Contributor: Kaitlyn Fallow (kmfallow@protonmail.com)

Citation
Unpublished at time of writing. 

General information
Data are from a recognition memory study conducted in 2016 by Kaitlyn Fallow, supervised by D. Stephen Lindsay at the University Of Victoria. Participants studied 96 items (bookended by 3 primacy and 3 recency buffers) for 1 s each (with a 900-ms inter-stimulus interval including a 500-ms central fixation cross). Study instructions were simply to try to remember each item as well as possible for a later memory test. Following a ~5-min filler task, participants then completed a self-paced recognition test comprising all studied items and an equal number of new items, randomly intermixed. Data are complete with the exception of exclusions that were deemed invalidating at the time of data collection (i.e., not performance-based; both exclusions were from the faces condition, one for misunderstanding the filler task and focusing on the studied faces during this period, and one for starting early and thus having an unusually long delay between study and test). Additionally, computer errors during data collection for this project produced blank data files or files missing large numbers of trials for an unknown number of subjects; these data were unrecoverable, so never made it to the analysis stage.

Stimulus
Indicates true old/new status (1 = studied, 2 = not studied).

Response
Participants' response collapsed into binary old/new variable (1 = studied, 2 = not studied).

Confidence scale
The Confidence variable in this file has been coded as 1 = maybe, 2 = probably, 3 = definitely to facilitate comparison with other datasets. Confidence and old/new judgments were made simultaneously on a 6-pt scale (1 = "definitely not studied", 2 = "probably not studied", 3 = "maybe not studied", 4 = "maybe studied", 5 = "probably studied", 6 = "definitely studied"); these original responses are included under Resp_raw for those preferring to work with data in this format.

Manipulations
Stimulus materials were manipulated between subjects, and were either high-resolution scans of lesser known masterwork paintings (from a set assembled by Jeffrey P. Toth), or photographs of faces (20-29 year olds with neutral expressions from Minear & Park, 2004, Behav Res Meth Ins C; http://agingmind.utdallas.edu/download-stimuli/face-database/). Materials type is indicated in the Condition column. The Stim_idx column includes unique stimulus identifiers.

Block size
All participants completed 192 trials as a single block.

Feedback
No feedback was provided.

NaN fields
A computer error produced incomplete data for a few subjects that could be mostly recovered using E-Prime's E-Recovery program, with the exception of the very last trial.

Subject population
Participants were undergraduate Psychology students at the University Of Victoria who participated in exchange for optional bonus course credit. Demographic data are not available for this particular sample, but the sample was drawn from a participant pool of mostly female-identifying individuals between the ages of 18 and 25 (~72% and ~79%, respectively, as of 2019; exact percentages may have differed at the time data were collected, but overall composition is roughly typical of previous years).

Response device
Keyboard

Experiment setting
Groups (maximum of 20 people/session; most often 5-15 participants/session, but anywhere from 1-20 possible), in lab

Training
None

Experiment goal
This experiment was part of an ongoing research line exploring materials-based differences in recognition memory response bias (see e.g., Lindsay & Kantner, 2011, https://doi.org/10.1057/9780230305281_11; Lindsay, Kantner, & Fallow, 2015, in https://doi.org/10.4324/9781315752808). Here we conducted a partial replication of the work in Fallow_unpub_1 to address the question of whether response bias differs between paintings and faces in a between-subjects context, as sample sizes in the previous experiment were inadvisably low for addressing this question.

Main result
Response bias (c) was significantly conservative in both groups, but did not differ significantly between the paintings and faces groups.

Materials
Paintings are available at https://osf.io/eya5x/. To map the numbers in Stim_idx to individual painting images, please consult the key (paintings_key.csv): paint_id reflects the numbering system for the bitmap files in the accompanying archive, whereas the numbering in this experiment is indicated in the mbbe_12r column. Face stimuli can be requested from Minear and Park at http://agingmind.utdallas.edu/download-stimuli/face-database/, and I can provide a key for mapping the face #s in our data file to individual faces in their set upon request.

Experiment dates
September – November 2016

Location of data collection
Dr. Stephen Lindsay’s lab at the University of Victoria, Victoria, BC, Canada